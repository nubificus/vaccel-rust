// SPDX-License-Identifier: Apache-2.0

syntax = "proto3";

package vaccel;

import "error.proto";

message TensorflowModelLoadRequest {
	int64 session_id = 1;
	int64 model_id = 2;
}

message TensorflowModelLoadResponse {
	bytes graph_def = 1;

	optional VaccelStatus status = 2;
}

message TensorflowModelUnloadRequest {
	int64 session_id = 1;
	int64 model_id = 2;
}

message TensorflowModelUnloadResponse {
	optional VaccelStatus status = 1;
}

enum TFDataType {
	// Add unused value here so that we are compatible
	// with what vAccelRT returns us
	UNUSED = 0;
	FLOAT = 1;
	DOUBLE = 2;
	INT32 = 3;  // Int32 tensors are always in 'host' memory.
	UINT8 = 4;
	INT16 = 5;
	INT8 = 6;
	STRING = 7;
	COMPLEX = 8;    // Old identifier kept for API backwards compatibility
	INT64 = 9;
	BOOL = 10;
	QINT8 = 11;     // Quantized int8
	QUINT8 = 12;    // Quantized uint8
	QINT32 = 13;    // Quantized int32
	BFLOAT16 = 14;  // Float32 truncated to 16 bits.  Only for cast ops.
	QINT16 = 15;    // Quantized int16
	QUINT16 = 16;   // Quantized uint16
	UINT16 = 17;
	COMPLEX128 = 18;  // Double-precision complex
	HALF = 19;
	RESOURCE = 20;
	VARIANT = 21;
	UINT32 = 22;
	UINT64 = 23;
}

message TFTensor {
	// Data of the tensor
	bytes data = 1;

	// Dimensions of the tensor
	repeated int64 dims = 2;

	// Data type
	TFDataType type = 3;
}

message TFNode {
	// Name of the node
	string name = 1;

	// Id of the node
	int32 id = 2;
}

message TensorflowModelRunRequest {
	int64 session_id = 1;
	int64 model_id = 2;

	// Run options
	bytes run_options = 3;

	// Input nodes & tensors
	repeated TFNode in_nodes = 4;
	repeated TFTensor in_tensors = 5;

	// Output nodes
	repeated TFNode out_nodes = 6;
}

message TensorflowModelRunResponse {
	// An inference result is a number of output tensors
	repeated TFTensor out_tensors = 1;

	optional VaccelStatus status = 2;
}

/* TFLite */

message TensorflowLiteModelLoadRequest {
	int64 session_id = 1;
	int64 model_id = 2;
}

message TensorflowLiteModelUnloadRequest {
	int64 session_id = 1;
	int64 model_id = 2;
}

enum TFLiteType {
	// Add unused value here so that we are compatible
	// with what vAccelRT returns us
	UNUSED = 0;
	NOTYPE = 1;
	FLOAT32 = 2;
	INT32 = 3;
	UINT8 = 4;
	INT64 = 5;
	STRING = 6;
	BOOL = 7;
	INT16 = 8;
	COMPLEX64 = 9;
	INT8 = 10;
	FLOAT16 = 11;
	FLOAT64 = 12;
	COMPLEX128 = 13;
	UINT64 = 14;
	RESOURCE = 15;
	VARIANT = 16;
	UINT32 = 17;
	UINT16 = 18;
	INT4 = 19;
}

message TFLiteTensor {
	// Data of the tensor
	bytes data = 1;

	// Dimensions of the tensor
	repeated int32 dims = 2;

	// Data type
	TFLiteType type = 3;
}

message TensorflowLiteModelRunRequest {
	int64 session_id = 1;
	int64 model_id = 2;

	// Input tensors
	repeated TFLiteTensor in_tensors = 3;
	// Number of output tensors
	int32 nr_outputs = 4;
}

message TensorflowLiteModelRunResponse {
	// An inference result is a number of output tensors
	repeated TFLiteTensor out_tensors = 1;

	optional VaccelStatus status = 2;
}
